{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLURM scheduler conveniences\n",
    "Dask jobqueue is currently able to scale a cluster for exactly one batch partition only. For work sessions to be as smooth as possible the scientific user needs to be enabled to do an informed decision about the batch partition to use. This Jupyter notebook collects a few tools that are, or might be useful, in achieving exactly that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idle compute nodes\n",
    "\n",
    "A simple SLURM command that filters the reported node state information for the number of currently idle nodes.\n",
    "\n",
    "Problem: On JUWELS, I did not experienced this to be very helpful to understand if it is possible to successfully get nodes from e.g. the `batch` partition. During my experiments it worked sufficiently reliable only for the `esm` and `devel` partitions. Haven't tried to get a structured overview on every partition here, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTITION AVAIL NODES STATE\n",
      "batch*       up  1562  idle\n",
      "devel        up    15  idle\n",
      "mem192       up   220  idle\n",
      "esm          up     4  idle\n",
      "large      down  1562  idle\n",
      "gpus         up    21  idle\n",
      "develgpus    up     8  idle\n",
      "maint        up  1610  idle\n"
     ]
    }
   ],
   "source": [
    "sinfo -t idle --format=\"%9P %.5a %.5D %.5t\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job start-up time estimate\n",
    "Problem: This doesn't take into account the scheduler backfilling mechanism and is therefore also not very accurate. Though, certainly more specific than the idle node count above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat > scheduling.sh << EOF\n",
    "#!/usr/bin/env bash\n",
    "#SBATCH -J dask-worker\n",
    "#SBATCH --cpus-per-task=96\n",
    "#SBATCH --mem=79G\n",
    "#SBATCH --test-only\n",
    "hostname\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov  9 18:32:41 CET 2020\n",
      "##### batch ##### \n",
      "sbatch: Job 3028245 to start at 2020-11-10T05:49:42 using 576 processors on nodes jwc01n[231-236] in partition batch\n",
      "##### devel ##### \n",
      "sbatch: Job 3028246 to start at 2020-11-09T18:32:42 using 576 processors on nodes jwc00n[016-021] in partition devel\n",
      "##### mem192 ##### \n",
      "sbatch: Job 3028247 to start at 2020-11-10T15:32:42 using 576 processors on nodes jwc08n[280-285] in partition mem192\n",
      "##### esm ##### \n",
      "allocation failure: Requested node configuration is not available\n",
      "##### large ##### \n",
      "sbatch: Job 3028249 to start at 2020-11-09T18:32:43 using 576 processors on nodes jwc01n[231-236] in partition large\n",
      "##### gpus ##### \n",
      "allocation failure: Invalid generic resource (gres) specification\n",
      "##### develgpus ##### \n",
      "allocation failure: Invalid generic resource (gres) specification\n",
      "##### maint ##### \n",
      "allocation failure: Invalid account or account/partition combination specified\n"
     ]
    }
   ],
   "source": [
    "date && scontrol show partition | grep PartitionName | cut -f2 -d\"=\" | \\\n",
    "xargs -I {} bash -c \"echo '##### {} ##### '  && \\\n",
    "sbatch --account esmtst --time 00:15:00 --nodes 6 --partition {} scheduling.sh\"\n",
    "printf \"\" # prevent displaying of xargs non-zero exit codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLview for JUWELS\n",
    "\n",
    "Problem: Not all batch partitions are implemented and I have sometimes experienced connectivity problems with [the JUWELS LLview web page](https://llview.fz-juelich.de/LLweb/juwels/jobreport/login.php). Also, at least on JUWELS the remote client way as described in the docs [here](https://www.fz-juelich.de/ias/jsc/EN/Expertise/Support/Software/LLview/_node.html) is currently not working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idle node projection\n",
    "\n",
    "WIP: Can we inform users about what to expect for any partition during their workday in more detail? Of course the accuracy of this would heavily depend on the behaviour of other users submitting batch jobs on the system, but it would still be a nice feature to get a feeling about system occupation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    devel  R    1:04:33      1 jwc00n001 2020-11-09T19:28:18\n",
      "    devel  R       3:08      1 jwc00n002 2020-11-09T18:44:41\n",
      "    devel  R       3:08      1 jwc00n004 2020-11-09T18:44:41\n",
      "    devel  R       3:08      1 jwc00n007 2020-11-09T18:44:42\n",
      "develgpus  R      43:10      1 jwc09n006 2020-11-09T19:49:40\n",
      "    devel  R      28:09      1 jwc00n013 2020-11-09T19:04:41\n"
     ]
    }
   ],
   "source": [
    "# this is only a starting point...\n",
    "squeue -o \"%.9P %.2t %.10M %.6D %R %e\" | grep devel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
